{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SDK version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
    "\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You have logged in. Now let us find all the subscriptions to which you have access...\n",
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "experiment_name = 'Capstone'\n",
    "project_folder = './pipeline-project'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "experiment\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name='covid-19-measures-and-deaths')\n",
    "df = dataset.to_pandas_dataframe()\n",
    "train_data = df.iloc[:-49]\n",
    "test_data = df.iloc[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# NOTE: update the cluster name to match the existing cluster\n",
    "# Choose a name for your CPU cluster\n",
    "amlcompute_cluster_name = \"worker\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "# compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.automl.core.forecasting_parameters import ForecastingParameters\n",
    "\n",
    "forecasting_parameters = ForecastingParameters(time_column_name='week', \n",
    "                                               forecast_horizon=10,\n",
    "                                               time_series_id_column_names=[\"country\"],\n",
    "                                               freq='W',\n",
    "                                               target_lags='auto',\n",
    "                                               target_rolling_window_size=20)\n",
    "\n",
    "automl_config = AutoMLConfig(task='forecasting',                             \n",
    "                             primary_metric='normalized_root_mean_squared_error',\n",
    "                             blocked_models = ['ExtremeRandomTrees', 'AutoArima', 'Prophet'],       \n",
    "                             experiment_timeout_hours=0.3,\n",
    "                             training_data=dataset,\n",
    "                             label_column_name='rate_14_day',\n",
    "                             compute_target=compute_target,\n",
    "                             enable_early_stopping=False,\n",
    "                             n_cross_validations=3,                             \n",
    "                             verbosity=logging.INFO,\n",
    "                             forecasting_parameters=forecasting_parameters)                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=metrics_output_name,\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='model_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=best_model_output_name,\n",
    "                           training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_step = AutoMLStep(\n",
    "    name='automl_module',\n",
    "    automl_config=automl_config,\n",
    "    outputs=[metrics_data, model_data],\n",
    "    allow_reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "pipeline = Pipeline(\n",
    "    description=\"Covid-19-aftermath-2\",\n",
    "    workspace=ws,    \n",
    "    steps=[automl_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step automl_module [4b55cd7b][a8a63811-5fc7-49af-904f-cd8c8809c637], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 98aeb11b-29e0-44d2-baaa-86aef460932e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Capstone/runs/98aeb11b-29e0-44d2-baaa-86aef460932e?wsid=/subscriptions/f08c5f25-28be-4c21-993c-ad64d5c84d3a/resourcegroups/ML/workspaces/capstone\n"
     ]
    }
   ],
   "source": [
    "remote_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e50ff0d0e9f46519514465b577f857f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/Capstone/runs/98aeb11b-29e0-44d2-baaa-86aef460932e?wsid=/subscriptions/f08c5f25-28be-4c21-993c-ad64d5c84d3a/resourcegroups/ML/workspaces/capstone\", \"run_id\": \"98aeb11b-29e0-44d2-baaa-86aef460932e\", \"run_properties\": {\"run_id\": \"98aeb11b-29e0-44d2-baaa-86aef460932e\", \"created_utc\": \"2021-02-03T19:03:37.263173Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-02-03T19:28:03.003944Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.98aeb11b-29e0-44d2-baaa-86aef460932e/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=FgKofRuA8v%2Ft2nZUAoZdJ0%2Fqd04Z7X%2F6KFmnIqZR8WE%3D&st=2021-02-04T11%3A30%3A58Z&se=2021-02-04T19%3A40%3A58Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.98aeb11b-29e0-44d2-baaa-86aef460932e/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=g%2FD4D1CV7T3Ac%2FRhzHaciCxBN5TBAJkw38ONXbsIy%2FQ%3D&st=2021-02-04T11%3A30%3A59Z&se=2021-02-04T19%3A40%3A59Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.98aeb11b-29e0-44d2-baaa-86aef460932e/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=rebH7IXwCgLsjkma65EDPJEP5X0NTRa6vY%2B%2F1te%2FkWo%3D&st=2021-02-04T11%3A30%3A59Z&se=2021-02-04T19%3A40%3A59Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:24:25\"}, \"child_runs\": [{\"run_id\": \"44a8bc42-8dba-453b-a4d4-1391a7425cf2\", \"name\": \"automl_module\", \"status\": \"Finished\", \"start_time\": \"2021-02-03T19:04:08.039425Z\", \"created_time\": \"2021-02-03T19:03:47.409253Z\", \"end_time\": \"2021-02-03T19:27:33.494855Z\", \"duration\": \"0:23:46\", \"run_number\": 136, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-02-03T19:03:47.409253Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-02-03 19:03:47Z] Submitting 1 runs, first five are: 4b55cd7b:44a8bc42-8dba-453b-a4d4-1391a7425cf2\\n[2021-02-03 19:28:02Z] Completing processing run id 44a8bc42-8dba-453b-a4d4-1391a7425cf2.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"ddd0d088\": {\"node_id\": \"ddd0d088\", \"name\": \"covid-19-measures-and-deaths\"}}, \"module_nodes\": {\"4b55cd7b\": {\"node_id\": \"4b55cd7b\", \"name\": \"automl_module\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"44a8bc42-8dba-453b-a4d4-1391a7425cf2\"}}, \"edges\": [{\"source_node_id\": \"ddd0d088\", \"source_node_name\": \"covid-19-measures-and-deaths\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"4b55cd7b\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"44a8bc42-8dba-453b-a4d4-1391a7425cf2\", \"name\": \"automl_module\", \"status\": \"Finished\", \"start_time\": \"2021-02-03T19:04:08.039425Z\", \"created_time\": \"2021-02-03T19:03:47.409253Z\", \"end_time\": \"2021-02-03T19:27:33.494855Z\", \"duration\": \"0:23:46\", \"run_number\": 136, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-02-03T19:03:47.409253Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PipelineRunId: 98aeb11b-29e0-44d2-baaa-86aef460932e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Capstone/runs/98aeb11b-29e0-44d2-baaa-86aef460932e?wsid=/subscriptions/f08c5f25-28be-4c21-993c-ad64d5c84d3a/resourcegroups/ML/workspaces/capstone\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 44a8bc42-8dba-453b-a4d4-1391a7425cf2\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Capstone/runs/44a8bc42-8dba-453b-a4d4-1391a7425cf2?wsid=/subscriptions/f08c5f25-28be-4c21-993c-ad64d5c84d3a/resourcegroups/ML/workspaces/capstone\n",
      "StepRun( automl_module ) Status: NotStarted\n",
      "StepRun( automl_module ) Status: Running\n",
      "\n",
      "StepRun(automl_module) Execution Summary\n",
      "=========================================\n",
      "StepRun( automl_module ) Status: Finished\n",
      "{'runId': '44a8bc42-8dba-453b-a4d4-1391a7425cf2', 'target': 'worker', 'status': 'Completed', 'startTimeUtc': '2021-02-03T19:04:08.039425Z', 'endTimeUtc': '2021-02-03T19:27:33.494855Z', 'properties': {'ContentSnapshotId': '5b8b2fab-3149-4d84-95f9-9c849c985a6a', 'StepType': 'AutoMLStep', 'azureml.moduleid': 'a8a63811-5fc7-49af-904f-cd8c8809c637', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '4b55cd7b', 'azureml.pipelinerunid': '98aeb11b-29e0-44d2-baaa-86aef460932e', 'num_iterations': '1000', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'normalized_root_mean_squared_error', 'train_split': '0', 'MaxTimeSeconds': None, 'acquisition_parameter': '0', 'num_cross_validation': '3', 'target': 'worker', 'RawAMLSettingsString': None, 'AMLSettingsJsonString': '{\"path\": null, \"name\": \"placeholder\", \"subscription_id\": \"f08c5f25-28be-4c21-993c-ad64d5c84d3a\", \"resource_group\": \"ML\", \"workspace_name\": \"capstone\", \"region\": \"westeurope\", \"compute_target\": \"worker\", \"spark_service\": null, \"azure_service\": null, \"many_models\": false, \"pipeline_fetch_max_batch_size\": 1, \"iterations\": 1000, \"primary_metric\": \"normalized_root_mean_squared_error\", \"task_type\": \"regression\", \"data_script\": null, \"validation_size\": 0.0, \"n_cross_validations\": 3, \"y_min\": null, \"y_max\": null, \"num_classes\": null, \"featurization\": \"auto\", \"_ignore_package_version_incompatibilities\": false, \"is_timeseries\": true, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 1, \"iteration_timeout_minutes\": null, \"mem_in_mb\": null, \"enforce_time_on_windows\": true, \"experiment_timeout_minutes\": 18, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": [\"ExtremeRandomTrees\", \"AutoArima\", \"Prophet\"], \"supported_models\": [\"KNN\", \"XGBoostRegressor\", \"ExtremeRandomTrees\", \"LassoLars\", \"GradientBoosting\", \"SGD\", \"Naive\", \"RandomForest\", \"DecisionTree\", \"SeasonalAverage\", \"SeasonalNaive\", \"AutoArima\", \"Average\", \"TensorFlowLinearRegressor\", \"TensorFlowDNN\", \"LightGBM\", \"TCNForecaster\", \"ElasticNet\", \"Prophet\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"_debug_log\": \"automl.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": \"STANDARD_D2_V2\", \"telemetry_verbosity\": 20, \"send_telemetry\": true, \"enable_dnn\": false, \"scenario\": \"SDK-1.13.0\", \"environment_label\": null, \"force_text_dnn\": false, \"enable_feature_sweeping\": false, \"time_column_name\": \"week\", \"grain_column_names\": [\"country\"], \"drop_column_names\": [], \"max_horizon\": 10, \"dropna\": false, \"overwrite_columns\": true, \"transform_dictionary\": {\"min\": \"_automl_target_col\", \"max\": \"_automl_target_col\", \"mean\": \"_automl_target_col\"}, \"window_size\": 20, \"country_or_region\": null, \"lags\": {\"_automl_target_col\": [\"auto\"]}, \"feature_lags\": null, \"seasonality\": \"auto\", \"use_stl\": null, \"short_series_handling\": true, \"freq\": \"W\", \"short_series_handling_configuration\": \"auto\", \"enable_early_stopping\": false, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_ensembling\": true, \"enable_stack_ensembling\": false, \"ensemble_iterations\": 15, \"enable_tf\": false, \"enable_subsampling\": false, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"track_child_runs\": true, \"allowed_private_models\": [], \"label_column_name\": \"rate_14_day\", \"weight_column_name\": null, \"cv_split_column_names\": null, \"enable_local_managed\": false, \"_local_managed_run_id\": null, \"cost_mode\": 1, \"lag_length\": 0, \"metric_operation\": \"minimize\", \"preprocess\": true}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\": {\\\\\"datasetId\\\\\": \\\\\"bd2a4a1a-5ce5-4b9e-8928-57c5da53f0da\\\\\"}, \\\\\"datasets\\\\\": 0}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'Orchestrator': 'automl', 'ClientType': 'Others', '_aml_system_scenario_identification': 'Remote.Parent', 'root_attribution': 'azureml.StepRun', 'snapshotId': '5b8b2fab-3149-4d84-95f9-9c849c985a6a', 'SetupRunId': '44a8bc42-8dba-453b-a4d4-1391a7425cf2_setup', 'SetupRunContainerId': 'dcid.44a8bc42-8dba-453b-a4d4-1391a7425cf2_setup', 'forecasting_target_lags': '[0]', 'forecasting_target_rolling_window_size': '20', 'forecasting_max_horizon': '10', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": false, \"subsampling\": false, \"dataset_classes\": 1279, \"dataset_features\": 141, \"dataset_samples\": 14730, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': '44a8bc42-8dba-453b-a4d4-1391a7425cf2_ModelExplain'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.44a8bc42-8dba-453b-a4d4-1391a7425cf2/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=57DKOGDZciVuFEI5spAvhpsqN9T7YmLVrA4syCpvI0M%3D&st=2021-02-03T18%3A53%3A51Z&se=2021-02-04T03%3A03%3A51Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.44a8bc42-8dba-453b-a4d4-1391a7425cf2/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=IPB2mXtiAmeEGWyxvDfwO3fOUEkmh7cn0LMIeAAp0Tg%3D&st=2021-02-03T18%3A53%3A51Z&se=2021-02-04T03%3A03%3A51Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.44a8bc42-8dba-453b-a4d4-1391a7425cf2/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=9L9BLQvgojBWmeeN1T3%2BYZs%2BPpPyYK9u0CweDhFjP9o%3D&st=2021-02-03T18%3A53%3A51Z&se=2021-02-04T03%3A03%3A51Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '98aeb11b-29e0-44d2-baaa-86aef460932e', 'status': 'Completed', 'startTimeUtc': '2021-02-03T19:03:40.265953Z', 'endTimeUtc': '2021-02-03T19:28:03.003944Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.98aeb11b-29e0-44d2-baaa-86aef460932e/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=l7rFIjzidHlmZRTOAy9lPeYYfXMOCBt2pzZixHWCIIs%3D&st=2021-02-03T18%3A54%3A00Z&se=2021-02-04T03%3A04%3A00Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.98aeb11b-29e0-44d2-baaa-86aef460932e/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=mLqZ3wcEbp4ijOojbAwzIquKR5%2FipXoi2byJrKRE6BI%3D&st=2021-02-03T18%3A54%3A00Z&se=2021-02-04T03%3A04%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://capstone5759293395.blob.core.windows.net/azureml/ExperimentRun/dcid.98aeb11b-29e0-44d2-baaa-86aef460932e/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=mJMxqU60nvkeJ%2B8WwgcIEmhrTTvcX%2BtmjbvK4gZhoOQ%3D&st=2021-02-03T18%3A54%3A00Z&se=2021-02-04T03%3A04%3A00Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "remote_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading azureml/44a8bc42-8dba-453b-a4d4-1391a7425cf2/metrics_data\nDownloaded azureml/44a8bc42-8dba-453b-a4d4-1391a7425cf2/metrics_data, 1 files out of an estimated total of 1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_9  \\\n",
       "spearman_correlation                                    [0.40353147592254274]   \n",
       "root_mean_squared_error                                   [100.0008986999376]   \n",
       "explained_variance                                      [0.08044031853338114]   \n",
       "mean_absolute_percentage_error                            [81.13323208072512]   \n",
       "mean_absolute_error                                      [62.707741225283236]   \n",
       "normalized_mean_absolute_error                          [0.45988185788633235]   \n",
       "normalized_median_absolute_error                        [0.45249666966976226]   \n",
       "normalized_root_mean_squared_error                       [0.5218879436360401]   \n",
       "median_absolute_error                                     [43.94179548773544]   \n",
       "normalized_root_mean_squared_log_error                   [0.4155024234458735]   \n",
       "r2_score                                                [-0.3948938151332912]   \n",
       "root_mean_squared_log_error                              [1.6600642508915096]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_11  \\\n",
       "spearman_correlation                                     [0.36351101684319076]   \n",
       "root_mean_squared_error                                   [102.85826886741312]   \n",
       "explained_variance                                      [0.051386602154377625]   \n",
       "mean_absolute_percentage_error                              [79.3949240741931]   \n",
       "mean_absolute_error                                        [65.37063839241785]   \n",
       "normalized_mean_absolute_error                           [0.47440617895770726]   \n",
       "normalized_median_absolute_error                          [0.4638839921251466]   \n",
       "normalized_root_mean_squared_error                        [0.5364075059939419]   \n",
       "median_absolute_error                                      [45.63646570964942]   \n",
       "normalized_root_mean_squared_log_error                    [0.4399003217940766]   \n",
       "r2_score                                                 [-0.4800660156331857]   \n",
       "root_mean_squared_log_error                               [1.7186404295269924]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_15  \\\n",
       "spearman_correlation                                      [0.3896775082971899]   \n",
       "root_mean_squared_error                                    [100.1025082729213]   \n",
       "explained_variance                                       [0.07983895261695832]   \n",
       "mean_absolute_percentage_error                             [80.60154085823875]   \n",
       "mean_absolute_error                                       [62.654052463437914]   \n",
       "normalized_mean_absolute_error                            [0.4582604595083159]   \n",
       "normalized_median_absolute_error                          [0.4511382286110013]   \n",
       "normalized_root_mean_squared_error                        [0.5221081167105387]   \n",
       "median_absolute_error                                     [44.392064490902534]   \n",
       "normalized_root_mean_squared_log_error                   [0.41722855449933854]   \n",
       "r2_score                                                [-0.39836153621611886]   \n",
       "root_mean_squared_log_error                               [1.6760717619053989]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_6  \\\n",
       "spearman_correlation                                    [0.28077991111011946]   \n",
       "root_mean_squared_error                                  [103.56747176154663]   \n",
       "explained_variance                                      [0.02965851369904619]   \n",
       "mean_absolute_percentage_error                            [81.97730025297462]   \n",
       "mean_absolute_error                                       [66.42502452194424]   \n",
       "normalized_mean_absolute_error                            [0.509836519023357]   \n",
       "normalized_median_absolute_error                         [0.4790497604507052]   \n",
       "normalized_root_mean_squared_error                       [0.5737360216415555]   \n",
       "median_absolute_error                                      [45.9895283087185]   \n",
       "normalized_root_mean_squared_log_error                    [0.546390955999756]   \n",
       "r2_score                                               [-0.48566202373411005]   \n",
       "root_mean_squared_log_error                                             [NaN]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_10  \\\n",
       "spearman_correlation                                      [0.3048358525256347]   \n",
       "root_mean_squared_error                                   [102.97167160845909]   \n",
       "explained_variance                                      [0.038253903253707956]   \n",
       "mean_absolute_percentage_error                             [79.35565045018737]   \n",
       "mean_absolute_error                                        [65.70967334187732]   \n",
       "normalized_mean_absolute_error                            [0.5017575824519348]   \n",
       "normalized_median_absolute_error                          [0.4762497730553157]   \n",
       "normalized_root_mean_squared_error                        [0.5629467913502152]   \n",
       "median_absolute_error                                     [44.954282498413086]   \n",
       "normalized_root_mean_squared_log_error                    [0.4907821763693858]   \n",
       "r2_score                                                 [-0.4701936463920912]   \n",
       "root_mean_squared_log_error                               [1.6190704473447632]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_8  \\\n",
       "spearman_correlation                                    [0.38947061467257615]   \n",
       "root_mean_squared_error                                  [102.66444876059082]   \n",
       "explained_variance                                     [0.048332843514884094]   \n",
       "mean_absolute_percentage_error                             [79.0198001685061]   \n",
       "mean_absolute_error                                       [65.13637987170641]   \n",
       "normalized_mean_absolute_error                          [0.47436353971302836]   \n",
       "normalized_median_absolute_error                        [0.46057272918146214]   \n",
       "normalized_root_mean_squared_error                       [0.5348115958935868]   \n",
       "median_absolute_error                                    [45.347768938869024]   \n",
       "normalized_root_mean_squared_log_error                  [0.43232099189707013]   \n",
       "r2_score                                               [-0.47585764229331234]   \n",
       "root_mean_squared_log_error                              [1.6669638641595201]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_7  \\\n",
       "spearman_correlation                                     [0.3853043429860778]   \n",
       "root_mean_squared_error                                  [100.01849365421896]   \n",
       "explained_variance                                      [0.06801796493876593]   \n",
       "mean_absolute_percentage_error                            [80.93503985065186]   \n",
       "mean_absolute_error                                       [62.03281895336452]   \n",
       "normalized_mean_absolute_error                           [0.4507198248822942]   \n",
       "normalized_median_absolute_error                        [0.43929444690352154]   \n",
       "normalized_root_mean_squared_error                       [0.5146740382746966]   \n",
       "median_absolute_error                                     [44.04806848155942]   \n",
       "normalized_root_mean_squared_log_error                  [0.41227978762265655]   \n",
       "r2_score                                               [-0.39784716891757427]   \n",
       "root_mean_squared_log_error                               [1.675112082493512]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_14  \\\n",
       "spearman_correlation                                      [0.3969186943123762]   \n",
       "root_mean_squared_error                                    [99.77442693579944]   \n",
       "explained_variance                                       [0.07822348498718786]   \n",
       "mean_absolute_percentage_error                             [78.95978674983108]   \n",
       "mean_absolute_error                                        [62.00344833212335]   \n",
       "normalized_mean_absolute_error                           [0.45452673371582436]   \n",
       "normalized_median_absolute_error                         [0.44157241212581505]   \n",
       "normalized_root_mean_squared_error                        [0.5216284438165718]   \n",
       "median_absolute_error                                      [42.36160897525254]   \n",
       "normalized_root_mean_squared_log_error                    [0.4385229587706949]   \n",
       "r2_score                                                [-0.38930095411084786]   \n",
       "root_mean_squared_log_error                               [1.7446333827292697]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_16  \\\n",
       "spearman_correlation                                      [0.4414623126400239]   \n",
       "root_mean_squared_error                                    [99.46762963021926]   \n",
       "explained_variance                                       [0.09041277878617375]   \n",
       "mean_absolute_percentage_error                              [77.6706240175627]   \n",
       "mean_absolute_error                                        [61.68936350626232]   \n",
       "normalized_mean_absolute_error                            [0.4479268076438143]   \n",
       "normalized_median_absolute_error                         [0.43695375126128283]   \n",
       "normalized_root_mean_squared_error                        [0.5121042950080438]   \n",
       "median_absolute_error                                     [42.480998333972416]   \n",
       "normalized_root_mean_squared_log_error                    [0.3945609092104227]   \n",
       "r2_score                                                [-0.38146389381273876]   \n",
       "root_mean_squared_log_error                                [1.569853444716861]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_12  \\\n",
       "spearman_correlation                                     [0.32622241755894743]   \n",
       "root_mean_squared_error                                   [102.80286388987992]   \n",
       "explained_variance                                        [0.0441851354753614]   \n",
       "mean_absolute_percentage_error                             [80.06304830772119]   \n",
       "mean_absolute_error                                         [65.8102917922793]   \n",
       "normalized_mean_absolute_error                            [0.5045665355906679]   \n",
       "normalized_median_absolute_error                         [0.47798966137565485]   \n",
       "normalized_root_mean_squared_error                         [0.566121361771821]   \n",
       "median_absolute_error                                       [44.5674317788232]   \n",
       "normalized_root_mean_squared_log_error                     [0.498585803226455]   \n",
       "r2_score                                                [-0.46386463043453313]   \n",
       "root_mean_squared_log_error                                              [NaN]   \n",
       "\n",
       "                                       44a8bc42-8dba-453b-a4d4-1391a7425cf2_13  \n",
       "spearman_correlation                                      [0.4047989932380913]  \n",
       "root_mean_squared_error                                   [102.41093849625473]  \n",
       "explained_variance                                      [0.057478210293567776]  \n",
       "mean_absolute_percentage_error                             [78.18086639822509]  \n",
       "mean_absolute_error                                        [64.99353531458563]  \n",
       "normalized_mean_absolute_error                           [0.47228260548563417]  \n",
       "normalized_median_absolute_error                         [0.46481152684894506]  \n",
       "normalized_root_mean_squared_error                        [0.5318678939796292]  \n",
       "median_absolute_error                                      [45.55476597745556]  \n",
       "normalized_root_mean_squared_log_error                    [0.4260180112761713]  \n",
       "r2_score                                                [-0.46897408926221046]  \n",
       "root_mean_squared_log_error                               [1.6776772735143604]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_9</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_11</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_15</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_6</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_10</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_8</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_7</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_14</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_16</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_12</th>\n      <th>44a8bc42-8dba-453b-a4d4-1391a7425cf2_13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>spearman_correlation</th>\n      <td>[0.40353147592254274]</td>\n      <td>[0.36351101684319076]</td>\n      <td>[0.3896775082971899]</td>\n      <td>[0.28077991111011946]</td>\n      <td>[0.3048358525256347]</td>\n      <td>[0.38947061467257615]</td>\n      <td>[0.3853043429860778]</td>\n      <td>[0.3969186943123762]</td>\n      <td>[0.4414623126400239]</td>\n      <td>[0.32622241755894743]</td>\n      <td>[0.4047989932380913]</td>\n    </tr>\n    <tr>\n      <th>root_mean_squared_error</th>\n      <td>[100.0008986999376]</td>\n      <td>[102.85826886741312]</td>\n      <td>[100.1025082729213]</td>\n      <td>[103.56747176154663]</td>\n      <td>[102.97167160845909]</td>\n      <td>[102.66444876059082]</td>\n      <td>[100.01849365421896]</td>\n      <td>[99.77442693579944]</td>\n      <td>[99.46762963021926]</td>\n      <td>[102.80286388987992]</td>\n      <td>[102.41093849625473]</td>\n    </tr>\n    <tr>\n      <th>explained_variance</th>\n      <td>[0.08044031853338114]</td>\n      <td>[0.051386602154377625]</td>\n      <td>[0.07983895261695832]</td>\n      <td>[0.02965851369904619]</td>\n      <td>[0.038253903253707956]</td>\n      <td>[0.048332843514884094]</td>\n      <td>[0.06801796493876593]</td>\n      <td>[0.07822348498718786]</td>\n      <td>[0.09041277878617375]</td>\n      <td>[0.0441851354753614]</td>\n      <td>[0.057478210293567776]</td>\n    </tr>\n    <tr>\n      <th>mean_absolute_percentage_error</th>\n      <td>[81.13323208072512]</td>\n      <td>[79.3949240741931]</td>\n      <td>[80.60154085823875]</td>\n      <td>[81.97730025297462]</td>\n      <td>[79.35565045018737]</td>\n      <td>[79.0198001685061]</td>\n      <td>[80.93503985065186]</td>\n      <td>[78.95978674983108]</td>\n      <td>[77.6706240175627]</td>\n      <td>[80.06304830772119]</td>\n      <td>[78.18086639822509]</td>\n    </tr>\n    <tr>\n      <th>mean_absolute_error</th>\n      <td>[62.707741225283236]</td>\n      <td>[65.37063839241785]</td>\n      <td>[62.654052463437914]</td>\n      <td>[66.42502452194424]</td>\n      <td>[65.70967334187732]</td>\n      <td>[65.13637987170641]</td>\n      <td>[62.03281895336452]</td>\n      <td>[62.00344833212335]</td>\n      <td>[61.68936350626232]</td>\n      <td>[65.8102917922793]</td>\n      <td>[64.99353531458563]</td>\n    </tr>\n    <tr>\n      <th>normalized_mean_absolute_error</th>\n      <td>[0.45988185788633235]</td>\n      <td>[0.47440617895770726]</td>\n      <td>[0.4582604595083159]</td>\n      <td>[0.509836519023357]</td>\n      <td>[0.5017575824519348]</td>\n      <td>[0.47436353971302836]</td>\n      <td>[0.4507198248822942]</td>\n      <td>[0.45452673371582436]</td>\n      <td>[0.4479268076438143]</td>\n      <td>[0.5045665355906679]</td>\n      <td>[0.47228260548563417]</td>\n    </tr>\n    <tr>\n      <th>normalized_median_absolute_error</th>\n      <td>[0.45249666966976226]</td>\n      <td>[0.4638839921251466]</td>\n      <td>[0.4511382286110013]</td>\n      <td>[0.4790497604507052]</td>\n      <td>[0.4762497730553157]</td>\n      <td>[0.46057272918146214]</td>\n      <td>[0.43929444690352154]</td>\n      <td>[0.44157241212581505]</td>\n      <td>[0.43695375126128283]</td>\n      <td>[0.47798966137565485]</td>\n      <td>[0.46481152684894506]</td>\n    </tr>\n    <tr>\n      <th>normalized_root_mean_squared_error</th>\n      <td>[0.5218879436360401]</td>\n      <td>[0.5364075059939419]</td>\n      <td>[0.5221081167105387]</td>\n      <td>[0.5737360216415555]</td>\n      <td>[0.5629467913502152]</td>\n      <td>[0.5348115958935868]</td>\n      <td>[0.5146740382746966]</td>\n      <td>[0.5216284438165718]</td>\n      <td>[0.5121042950080438]</td>\n      <td>[0.566121361771821]</td>\n      <td>[0.5318678939796292]</td>\n    </tr>\n    <tr>\n      <th>median_absolute_error</th>\n      <td>[43.94179548773544]</td>\n      <td>[45.63646570964942]</td>\n      <td>[44.392064490902534]</td>\n      <td>[45.9895283087185]</td>\n      <td>[44.954282498413086]</td>\n      <td>[45.347768938869024]</td>\n      <td>[44.04806848155942]</td>\n      <td>[42.36160897525254]</td>\n      <td>[42.480998333972416]</td>\n      <td>[44.5674317788232]</td>\n      <td>[45.55476597745556]</td>\n    </tr>\n    <tr>\n      <th>normalized_root_mean_squared_log_error</th>\n      <td>[0.4155024234458735]</td>\n      <td>[0.4399003217940766]</td>\n      <td>[0.41722855449933854]</td>\n      <td>[0.546390955999756]</td>\n      <td>[0.4907821763693858]</td>\n      <td>[0.43232099189707013]</td>\n      <td>[0.41227978762265655]</td>\n      <td>[0.4385229587706949]</td>\n      <td>[0.3945609092104227]</td>\n      <td>[0.498585803226455]</td>\n      <td>[0.4260180112761713]</td>\n    </tr>\n    <tr>\n      <th>r2_score</th>\n      <td>[-0.3948938151332912]</td>\n      <td>[-0.4800660156331857]</td>\n      <td>[-0.39836153621611886]</td>\n      <td>[-0.48566202373411005]</td>\n      <td>[-0.4701936463920912]</td>\n      <td>[-0.47585764229331234]</td>\n      <td>[-0.39784716891757427]</td>\n      <td>[-0.38930095411084786]</td>\n      <td>[-0.38146389381273876]</td>\n      <td>[-0.46386463043453313]</td>\n      <td>[-0.46897408926221046]</td>\n    </tr>\n    <tr>\n      <th>root_mean_squared_log_error</th>\n      <td>[1.6600642508915096]</td>\n      <td>[1.7186404295269924]</td>\n      <td>[1.6760717619053989]</td>\n      <td>[NaN]</td>\n      <td>[1.6190704473447632]</td>\n      <td>[1.6669638641595201]</td>\n      <td>[1.675112082493512]</td>\n      <td>[1.7446333827292697]</td>\n      <td>[1.569853444716861]</td>\n      <td>[NaN]</td>\n      <td>[1.6776772735143604]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "metrics_output = remote_run.get_pipeline_output(metrics_output_name)\n",
    "num_file_downloaded = metrics_output.download('.', show_progress=True)\n",
    "import json\n",
    "with open(metrics_output._path_on_datastore) as f:\n",
    "    metrics_output_result = f.read()\n",
    "    \n",
    "deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "df = pd.DataFrame(deserialized_metrics_output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading azureml/44a8bc42-8dba-453b-a4d4-1391a7425cf2/model_data\nDownloaded azureml/44a8bc42-8dba-453b-a4d4-1391a7425cf2/model_data, 1 files out of an estimated total of 1\n"
     ]
    }
   ],
   "source": [
    "# Retrieve best model from Pipeline Run\n",
    "best_model_output = remote_run.get_pipeline_output(best_model_output_name)\n",
    "num_file_downloaded = best_model_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ForecastingPipelineWrapper(pipeline=Pipeline(memory=None,\n",
       "                                             steps=[('timeseriestransformer',\n",
       "                                                     TimeSeriesTransformer(featurization_config=None,\n",
       "                                                                           pipeline_type=<TimeSeriesPipelineType.FULL: 1>)),\n",
       "                                                    ('prefittedsoftvotingregressor',\n",
       "                                                     PreFittedSoftVotingRegressor(estimators=[('7',\n",
       "                                                                                               Pipeline(memory=None,\n",
       "                                                                                                        steps=[('robustscaler',\n",
       "                                                                                                                RobustScaler(copy=True,\n",
       "                                                                                                                             quantile_range=[10,\n",
       "                                                                                                                                             9...\n",
       "                                                                                                                                      min_impurity_decrease=0.0,\n",
       "                                                                                                                                      min_impurity_split=None,\n",
       "                                                                                                                                      min_samples_leaf=0.013373400896808276,\n",
       "                                                                                                                                      min_samples_split=0.07532221397586239,\n",
       "                                                                                                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                                                                                                      presort='deprecated',\n",
       "                                                                                                                                      random_state=None,\n",
       "                                                                                                                                      splitter='best'))],\n",
       "                                                                                                        verbose=False))],\n",
       "                                                                                  weights=[0.3333333333333333,\n",
       "                                                                                           0.4666666666666667,\n",
       "                                                                                           0.06666666666666667,\n",
       "                                                                                           0.06666666666666667,\n",
       "                                                                                           0.06666666666666667]))],\n",
       "                                             verbose=False),\n",
       "                           stddev=None)"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
    "    best_model = pickle.load(f)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of last data per country\n",
    "forecast_context = train_data[train_data.country=='Netherlands'][-5:]\n",
    "# repeat the last row 12 times\n",
    "test_set = pd.DataFrame(np.repeat(forecast_context[-1:].values, 12, axis=0))\n",
    "test_set.columns = forecast_context.columns\n",
    "\n",
    "# make a daterange in the future\n",
    "forecast_horizon = pd.date_range(pd.Timestamp(2021, 2, 4), pd.Timestamp(2021, 4, 30), freq=\"W\")\n",
    "\n",
    "X_forecast = test_set.reset_index()\n",
    "X_forecast['week'] = forecast_horizon\n",
    "X_forecast['index'] = forecast_horizon\n",
    "X_forecast = X_forecast.set_index('index')\n",
    "\n",
    "# test_labels = test_set.pop('rate_14_day').values\n",
    "# forecast_context.pop('rate_14_day').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([67.5262697151971, 67.5262697151971, 67.5262697151971,\n",
       "       67.5262697151971, 67.5262697151971, 67.5262697151971, nan, nan,\n",
       "       nan, nan, nan, nan], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 220
    }
   ],
   "source": [
    "test_labels = X_forecast['rate_14_day'].values\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the forecast context to the horizon\n",
    "# X_forecast = forecast_context.append(X_forecast)\n",
    "test_labels = X_forecast['rate_14_day'].values\n",
    "test_labels = test_labels.fill(np.NaN)\n",
    "\n",
    "label_fcst, data_trans = best_model.forecast(X_forecast, y_pred=test_labels,ignore_data_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_fcst, data_trans = best_model.forecast(forecast_destination=pd.Timestamp(2021, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   _automl_target_col\n",
       "week       country     origin                        \n",
       "2021-02-07 Netherlands 2021-01-31              111.54\n",
       "2021-02-14 Netherlands 2021-01-31              111.54\n",
       "2021-02-21 Netherlands 2021-01-31              111.54\n",
       "2021-02-28 Netherlands 2021-01-31              111.54\n",
       "2021-03-07 Netherlands 2021-01-31              111.54\n",
       "2021-03-14 Netherlands 2021-01-31              111.54\n",
       "2021-03-21 Netherlands 2021-01-31              111.54\n",
       "2021-03-28 Netherlands 2021-01-31              111.54\n",
       "2021-04-04 Netherlands 2021-01-31               94.47\n",
       "2021-04-11 Netherlands 2021-01-31               94.47\n",
       "2021-04-18 Netherlands 2021-04-11               79.19\n",
       "2021-04-25 Netherlands 2021-04-11               79.19"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>_automl_target_col</th>\n    </tr>\n    <tr>\n      <th>week</th>\n      <th>country</th>\n      <th>origin</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-02-07</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>111.54</td>\n    </tr>\n    <tr>\n      <th>2021-02-14</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>111.54</td>\n    </tr>\n    <tr>\n      <th>2021-02-21</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>111.54</td>\n    </tr>\n    <tr>\n      <th>2021-02-28</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>111.54</td>\n    </tr>\n    <tr>\n      <th>2021-03-07</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>111.54</td>\n    </tr>\n    <tr>\n      <th>2021-03-14</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>111.54</td>\n    </tr>\n    <tr>\n      <th>2021-03-21</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>111.54</td>\n    </tr>\n    <tr>\n      <th>2021-03-28</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>111.54</td>\n    </tr>\n    <tr>\n      <th>2021-04-04</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>94.47</td>\n    </tr>\n    <tr>\n      <th>2021-04-11</th>\n      <th>Netherlands</th>\n      <th>2021-01-31</th>\n      <td>94.47</td>\n    </tr>\n    <tr>\n      <th>2021-04-18</th>\n      <th>Netherlands</th>\n      <th>2021-04-11</th>\n      <td>79.19</td>\n    </tr>\n    <tr>\n      <th>2021-04-25</th>\n      <th>Netherlands</th>\n      <th>2021-04-11</th>\n      <td>79.19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "source": [
    "data_trans[['_automl_target_col']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ForecastingPipelineWrapper(pipeline=Pipeline(memory=None,\n",
       "                                             steps=[('timeseriestransformer',\n",
       "                                                     TimeSeriesTransformer(featurization_config=None,\n",
       "                                                                           pipeline_type=<TimeSeriesPipelineType.FULL: 1>)),\n",
       "                                                    ('prefittedsoftvotingregressor',\n",
       "                                                     PreFittedSoftVotingRegressor(estimators=[('7',\n",
       "                                                                                               Pipeline(memory=None,\n",
       "                                                                                                        steps=[('robustscaler',\n",
       "                                                                                                                RobustScaler(copy=True,\n",
       "                                                                                                                             quantile_range=[10,\n",
       "                                                                                                                                             9...\n",
       "                                                                                                                                      min_impurity_decrease=0.0,\n",
       "                                                                                                                                      min_impurity_split=None,\n",
       "                                                                                                                                      min_samples_leaf=0.013373400896808276,\n",
       "                                                                                                                                      min_samples_split=0.07532221397586239,\n",
       "                                                                                                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                                                                                                      presort='deprecated',\n",
       "                                                                                                                                      random_state=None,\n",
       "                                                                                                                                      splitter='best'))],\n",
       "                                                                                                        verbose=False))],\n",
       "                                                                                  weights=[0.3333333333333333,\n",
       "                                                                                           0.4666666666666667,\n",
       "                                                                                           0.06666666666666667,\n",
       "                                                                                           0.06666666666666667,\n",
       "                                                                                           0.06666666666666667]))],\n",
       "                                             verbose=False),\n",
       "                           stddev=None)"
      ]
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Covid-19-deaths-forecaster\t1\n"
     ]
    }
   ],
   "source": [
    "remote_run.upload_file(\"outputs/my_model.pickle\", best_model_output._path_on_datastore)\n",
    "automl_model = remote_run.register_model(model_path=\"outputs/my_model.pickle\", model_name='Covid-19-deaths-forecaster', description='Forecast the number of deaths per 100.000 due to covid-19.')\n",
    "print(automl_model.name, automl_model.version, sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'deploy_model'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-239-368e3b5158ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mautoml_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeploy_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'deploy_model'"
     ]
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment.get(workspace, \"AzureML-Minimal\").clone(env_name)\n",
    "\n",
    "for pip_package in [\"scikit-learn\"]:\n",
    "    env.python.conda_dependencies.add_pip_package(pip_package)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='run.py', environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}